---
title: Hello，MySQL
date: 2023-11-10 14:03:43
tags:
  - tech
  - mysql
draft: true
hideInList: false
feature: 
isTop: false
---


# MySQL 概述
在程序员视角看来，用户发送请求到 Java 系统，Java 系统编写 SQL 语句去访问 MySQL 获得数据库的存储数据，进行增删查改。

接下来讲讲其中的一些部件：
- 需要发送网络请求才能进行访问，所以需要引入 **MySQL 驱动**的 jar 包。
- Java 系统部署在 Tomcat 上面，Tomcat 支持多线程请求。Java 线程请求不止一个，不可能等待单个 MySQL 驱动的线程，并且频繁创建会很消耗资源，因此 Java 系统和 MySQL 这两边都引入了**连接池**。

![image.png](https://bestkxt.oss-cn-guangzhou.aliyuncs.com/img/202311101415077.png)


按照上面这个图，MySQL 数据库服务器就会收到网络请求，比如一条 SQL。接下来MySQL 服务器这边就会有对应的部件来执行不同的工作：
- 线程：网络请求必须是让线程来处理，所以内部会开启一个工作线程处理。
- SQL 接口：作为接口，负责接收（和处理 SQL）
- SQL 解析器：解析 SQL 语句的含义
- 查询优化器：负责计算出最优的查询路径，或着也叫最优的查询计划
- 执行器：携带者最优查询计划去访问存储引擎，不断查询或者更新语句，直到得出想要的结果。比如查询到一条数据比对符不符合要求，不符合就接着查询
- 存储引擎：真正执行 SQL 语句的地方。这里可以有不同的存储引擎，存储引擎设计了一套先内存后磁盘的机制，确保查询速度足够快并且减轻磁盘访问压力。


<!--more-->


![image.png](https://bestkxt.oss-cn-guangzhou.aliyuncs.com/img/202311101446249.png)


# InnoDB 存储引擎

接下来说下底部存储引擎、内存、磁盘的一个关系。

假设现在有一条更新语句：update t_student set name = "lisi" where id = 1。需要把id=1的张三改名成李四。

## 执行顺序
- buffer pool:直接从磁盘更新文件太慢了，所以引入了缓存池，将磁盘文件读一份后放到内存里面，对内存进行操作会快的多。
- undo 日志：很多时候我们用到了事务，需要回滚。事务回滚就需要知道上一个被覆盖的值是什么，因此就有了undo日志。它的作用是写入数据的旧值，方便回滚。
- buffer pool:写入undo日志后，缓存池就先更新内存里面的数据。
- redo log buffer:在内存里面开辟出新的一块儿地方存放着SQL语句的操作，比如把张三改成了李四。
- redo log:存放在磁盘里面，当buffer在内存写完后就会再开始写磁盘。记录数据比如对“id=1这行记录修改了name字段的值为xxx”

## **redo log buffer写磁盘的时机控制**
有一个参数：innodb_flush_log_at_trx_commit来控制怎么写入？
- 0代表不写磁盘日志
- 1代表事务提交的时候必须写入redo日志（推荐）✅
- 2代表事务提交后可能过一段时间（比如一秒）再写入磁盘日志


## **宕机时机的影响**
- 假设第三步更新内存数据后宕机，那么就没写入磁盘，所以引入了redo日志用来恢复记录。
- 假设第四步做完宕机，那么内存里面的数据就都会丢失，事务也就会回滚，此时问题不大，一般就会报事务出错然后回滚回原来的状态即可。
- 假设第五步事务提交后宕机，那么此时MySQL并没有更新成功，这个时候重启MySQL就能使用redo日志重新进行更新。

![image.png](https://bestkxt.oss-cn-guangzhou.aliyuncs.com/img/202311101455891.png)


# Binlog
上面1~4其实都是更新SQL的过程，到了后面几步就是事务提交的一个过程。

其实在第五步redo日志刷入磁盘时，也会同步写入Binlog。这里区别一下概念：
- redo日志是物理上的概念，比如对着内存上的数据页的什么记录，做了什么修改。这个是innodb特有的
- Binlog是逻辑上的一个概念，比如学生表上面id=1的记录，更新后的值是什么。这个是MySQL自己特有的

## Binlog刷入时机控制
参数：sync_binlog
- 0代表先进入OS cache，晚点再刷入磁盘，宕机就会有风险
- 1代表事务提交了，就要强制刷入磁盘✅


## commit标记
第七步里面才会写入commit标记，代表整个事务提交了，如果在之前发生了宕机，那么此时事务都算不成功。

## 两阶段提交
我们来通过一个简单的例子来说明两阶段提交。

假设我们有一个在线购物系统，分布在不同地方的数据库处理订单。一个订单的处理可能涉及到减少库存、扣款等多个数据库的操作。现在我们要确保所有这些数据库的操作要么都成功，要么都失败，以避免因为一部分成功一部分失败导致的问题。

1. **准备阶段：**
    - 订单处理系统的主控制中心告诉每个数据库：“我们有一个订单要处理，你们准备好了吗？”
    - 每个数据库在本地进行准备工作，比如检查库存是否足够、用户账户是否有足够余额等。
    - 如果所有数据库都准备好了，它们会回应：“准备好了！”但此时它们并没有正式执行订单，只是表示可以执行。
2. **提交阶段：**
    - 主控制中心收到所有数据库的回应后，如果都是“准备好了”，那么它告诉它们：“可以执行订单了，大家一起来！”
    - 每个数据库执行实际的订单处理操作，比如减少库存、扣款等。
    - 如果所有数据库都成功执行了订单，它们会回应：“订单执行成功！”
    - 如果有任何一个数据库在执行过程中出了问题，它会回应：“订单执行失败！”
    - 如果所有数据库都成功，主控制中心最终告诉大家：“订单完成！”如果有一个数据库失败，主控制中心告诉大家：“订单取消！”

这样，无论是全部成功还是其中有一个失败，整个订单的状态都是一致的。如果有一个数据库执行失败，所有数据库都会回滚到事务开始的状态，确保数据的一致性。




![image.png](https://bestkxt.oss-cn-guangzhou.aliyuncs.com/img/202311101536549.png)

7步都完成后，那么就会有后台的线程将内存的脏数据一点点刷入磁盘了。

## 为什么不直接更新磁盘里的数据，而是通过IO线程不定时执行，这与性能和I/O效率有关：

- **性能：** 直接更新磁盘可能导致大量的I/O操作，影响性能。通过使用内存中的Buffer Pool，可以在内存中完成大部分读写操作，减少对磁盘的访问，提高性能。
    
- **事务隔离：** 数据库需要考虑多个事务同时进行的情况，为了保证事务的隔离性，它可能需要在内存中暂存多个事务的修改，最后一次性写入磁盘，而不是每次都即时写入。
    

总体而言，这些概念和机制的引入是为了平衡数据库的性能、可靠性和一致性。虽然增加了一些复杂性，但它们为数据库系统提供了更多的功能和优化选项。


# 机器配置
## Java机器配置
- 2核4G
- 4核8G,每秒钟可以抗下五百左右的并发访问量

## MySQL配置
- 8核16G,每秒钟可以抗下一两千左右的并发访问量
- 16核32G，每秒钟可以抗下三四左右的并发访问量

## 配置题
假设你开发的Java系统部署在一台4核8G的机器上，那么我们假设这个Java系统处理一个请 求非常非常快，每个请求只需要0.01ms就可以处理完了，那你觉得这一台机器部署的Java系统，可以实现每秒抗下几千并发 请求吗？可以实现每秒抗下几万并发请求吗？

如果每个请求只需要0.01毫秒（即10微秒）来处理，那么我们可以通过以下方式来估算它每秒抗下的并发请求量：
1. **计算每个核心的请求数：**
    - 1秒 = 1000毫秒，所以每个核心每秒可以处理的请求数为：1秒 / 0.01毫秒 = 100,000次。
2. **计算总的请求数：**
    - 如果系统有4个核心，那么总的每秒处理请求数为：4核心 * 100,000次/核心 = 400,000次/秒。
根据上述估算，这台4核8G的机器上的Java系统理论上每秒可以处理约40万次请求。
当然，这个估算是基于每个请求处理非常迅速的情况下得出的。实际上，系统的性能可能会受到其他因素的影响，比如内存大小、垃圾回收效率、网络带宽等。因此，在实际生产环境中，最好通过性能测试和基准测试来获取更准确的结果。


## 性能指标
- qps：每秒的请求数
- tps:每秒可处理的事务量，比如事务提交或者回滚的量
- 吞吐量：磁盘每秒可读写的字节数量，比如redo日志写磁盘
- iops:每秒可以执行的随机io请求数量，决定了内存脏数据刷回磁盘的效率
- lantency:磁盘读写延迟
- CPU负载
- 网络负载
- 内存负载

# buffer pool

